{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NobelPrize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "\n",
    "# 设置头文件\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',\n",
    "    'Cookie':'_hjSessionUser_1004842=eyJpZCI6IjFlNGNjM2U0LWI5YzItNTQ4Ni1iMDU1LTIwYTQyY2E3ODFmMyIsImNyZWF0ZWQiOjE2OTI5NDQzMTk5NTQsImV4aXN0aW5nIjp0cnVlfQ==; _hjSession_1004842=eyJpZCI6IjU5ODQzYWMwLTM0NmYtNGViOC1hNDg4LWY4ODk2MWQ0OTkzMiIsImNyZWF0ZWQiOjE2OTMzNjQ1MzY3NTUsImluU2FtcGxlIjpmYWxzZX0=; _hjAbsoluteSessionInProgress=0; _gid=GA1.2.1201900062.1693364537; cookieNotice=1; _ga=GA1.2.1573572851.1692944320; _ga_MY66JBWQGX=GS1.1.1693364536.4.1.1693364835.24.0.0'\n",
    "}\n",
    "\n",
    "def get_people(url_list):\n",
    "    \n",
    "    data = pd.DataFrame(columns=['FIELD', 'TIME', 'NAME', 'LINK'])\n",
    "    \n",
    "    for url in url_list:\n",
    "        # 获取获奖人数据\n",
    "        requests.packages.urllib3.disable_warnings()\n",
    "        html = requests.get(url, headers=headers, verify=False).text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # 获取存储学校数据的tr标签\n",
    "        a_list = soup.find_all('a')\n",
    "        for a in a_list:\n",
    "            if 'href' in a.attrs.keys() and re.match('https://www.nobelprize.org/prizes/(.*?)/(.*?)/(.*?)/facts/', a['href']):\n",
    "                info = list(re.findall('https://www.nobelprize.org/prizes/(.*?)/(.*?)/(.*?)/facts/', a['href'], re.S)[0])\n",
    "                FIELD = info[0]\n",
    "                TIME = info[1]\n",
    "                NAME = a.text.strip()\n",
    "                LINK = a['href']\n",
    "                value = [FIELD, TIME, NAME, LINK]\n",
    "                data.loc[len(data.index)] = value\n",
    "                print(value)    # 打印结果\n",
    "                \n",
    "    data.to_excel('NobelPrize(temp).xlsx', index=False)\n",
    "    return data\n",
    "\n",
    "def get_personal_info(data):\n",
    "    # 建立数据表存储最终数据\n",
    "    nobel = pd.DataFrame(columns=['FIELD', 'TIME', 'NAME', 'LINK', 'BORN_DATE', 'DIED_DATE','AFFILIATION', 'PRIZE_MOTIVATION', 'PRIZE_SHARE'])\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        FIELD, TIME, NAME, LINK = data.iloc[i, 0], data.iloc[i, 1], data.iloc[i, 2], data.iloc[i, 3]\n",
    "        requests.packages.urllib3.disable_warnings()\n",
    "        # 访问页面并解析\n",
    "        html = requests.get(LINK, headers=headers, verify=False).text\n",
    "        soup = BeautifulSoup(html, 'html')\n",
    "\n",
    "        try:\n",
    "            content = soup.find('div', class_='content')\n",
    "            ps = content.find_all('p')\n",
    "\n",
    "            if len(ps)==5:\n",
    "                BORN_DATE = ps[1].text.strip().replace('\\n','')[6:]\n",
    "                AFFILIATION = ps[2].text.strip().replace('\\n','')[37:]\n",
    "                PRIZE_MOTIVATION = ps[3].text[20:-2]\n",
    "                PRIZE_SHARE = ps[4].text[13:]\n",
    "\n",
    "                value = [FIELD, TIME, NAME, LINK, BORN_DATE, '', AFFILIATION, PRIZE_MOTIVATION, PRIZE_SHARE]\n",
    "\n",
    "            elif len(ps)==6 or len(ps)==7:\n",
    "                BORN_DATE = ps[1].text.strip().replace('\\n','')[6:]\n",
    "                DIED_DATE = ps[2].text.strip().replace('\\n','')[6:]\n",
    "                AFFILIATION = ps[3].text.strip().replace('\\n','')[37:]\n",
    "                PRIZE_MOTIVATION = ps[4].text[20:-2]\n",
    "                PRIZE_SHARE = ps[5].text[13:]\n",
    "\n",
    "                value = [FIELD, TIME, NAME, LINK, BORN_DATE, DIED_DATE, AFFILIATION, PRIZE_MOTIVATION, PRIZE_SHARE]\n",
    "\n",
    "            nobel.loc[len(nobel.index)] = value\n",
    "\n",
    "            print(value, 'success!')\n",
    "            time.sleep(random.randint(1, 3))\n",
    "\n",
    "        except:\n",
    "            value = [FIELD, TIME, NAME, LINK]\n",
    "            nobel.loc[len(nobel.index)] = value\n",
    "            print(value, 'fail!')\n",
    "\n",
    "url_list = ['https://www.nobelprize.org/prizes/lists/all-nobel-prizes-in-physics/',\\\n",
    "           'https://www.nobelprize.org/prizes/lists/all-nobel-prizes-in-chemistry/',\\\n",
    "           'https://www.nobelprize.org/prizes/lists/all-nobel-laureates-in-physiology-or-medicine/',\\\n",
    "           'https://www.nobelprize.org/prizes/lists/all-prizes-in-economic-sciences/',]\n",
    "data = get_people(url_list)\n",
    "nobel = get_personal_info(data)\n",
    "nobel.to_excel('NobelPrize.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
